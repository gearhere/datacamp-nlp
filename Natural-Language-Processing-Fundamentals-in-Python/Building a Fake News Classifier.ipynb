{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Classifying-Fake-News-using-Supervised-Learning-with-NLP\" data-toc-modified-id=\"Classifying-Fake-News-using-Supervised-Learning-with-NLP-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Classifying Fake News using Supervised Learning with NLP</a></span><ul class=\"toc-item\"><li><span><a href=\"#Supervised-learning-steps\" data-toc-modified-id=\"Supervised-learning-steps-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Supervised learning steps</a></span></li></ul></li><li><span><a href=\"#Building-word-count-vectors-with-scikit-learn\" data-toc-modified-id=\"Building-word-count-vectors-with-scikit-learn-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Building word count vectors with scikit-learn</a></span></li><li><span><a href=\"#Training-and-Testing-a-Classification-Model-with-scikit-learn\" data-toc-modified-id=\"Training-and-Testing-a-Classification-Model-with-scikit-learn-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training and Testing a Classification Model with scikit-learn</a></span></li><li><span><a href=\"#Simple-NLP,-Complex-Problems\" data-toc-modified-id=\"Simple-NLP,-Complex-Problems-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Simple NLP, Complex Problems</a></span></li><li><span><a href=\"#Extra-Links\" data-toc-modified-id=\"Extra-Links-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Extra Links</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Fake News using Supervised Learning with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to create supervised learning data from text?\n",
    " - Use bag-of-words models or tf-idf as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collect and preprocess our data\n",
    "- Determine a label (Example: Movie genre)\n",
    "- Split data into training and test sets\n",
    "- Extract features from the text to help predict the label\n",
    " - Bag-of-words vector built into scikit-learn\n",
    "- Evaluate trained model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df = ... # Load data into DataFrame\n",
    "y traditionally refers to the labels or outcome you want the model to earn\n",
    "y = df['Sci-Fi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['plot'],\n",
    "                                                    y, \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=53\n",
    "                                                    )\n",
    "training data: X_train\n",
    "training labels: y_train\n",
    "    \n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building word count vectors with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Import the necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df.label\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], y, test_size=0.33, random_state=53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# Print the head of count_df\n",
    "print(count_df.head())\n",
    "\n",
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing a Classification Model with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier\n",
    "\n",
    "Examples:\n",
    "- If the plot has a spaceship, how likely is it to be sci-fi?\n",
    "- Given a spaceship and an alien, how likely now is it sci-fi?\n",
    "\n",
    "Each word from `CountVectorizer` acts as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# evaluate model perormance\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# pass training count vectorizer & training labels\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# call predict with the count vectorizer test data\n",
    "pred = nb_classifier.predict(count_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**evaluation**\n",
    "\n",
    "```\n",
    "# test accuracy\n",
    "metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "# check the confusion matrix\n",
    "metrics.confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1,0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NLP, Complex Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Translation https://twitter.com/Lupintweets/status/865533182455685121\n",
    "\n",
    "- Sentiment Analysis https://nlp.stanford.edu/projects/socialsent/\n",
    "![wordsentiment](img/wordsentiment.png)\n",
    "\n",
    "- Language Biases https://www.youtube.com/watch?v=j7FwpZB1hWc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[学习规划|机器学习和NLP入门规划](https://www.pkudodo.com/2019/03/20/1-10/)\n",
    "\n",
    "[面试体会|微软、头条、滴滴、爱奇艺NLP面试感想](https://www.pkudodo.com/2019/03/10/1-9/)\n",
    "\n",
    "[为什么相比于计算机视觉(cv)，自然语言处理(nlp)领域的发展要缓慢？](https://www.zhihu.com/question/295962495)\n",
    "\n",
    "[自然语言处理有哪些方向适合独立研究？](https://www.zhihu.com/question/335289475)\n",
    "\n",
    "[调用jupyter notebook文件内的函数一种简单方法](https://blog.csdn.net/wangjian1204/article/details/67633614/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
